{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Teoria - Descida do gradiente.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPhtYj1/ZdTFRLdgizj+nn2"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"VOsLI92wg6BL","executionInfo":{"status":"ok","timestamp":1615654573742,"user_tz":180,"elapsed":1618,"user":{"displayName":"Guilherme Samuel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5zFr3jUWJ1NdrUB6KSy3C4B0uR2RLqUiKRzi0S2M=s64","userId":"17398030156076443435"}}},"source":["from sklearn.linear_model import LinearRegression\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"h-KabbeGhER0","executionInfo":{"status":"ok","timestamp":1615655460813,"user_tz":180,"elapsed":577,"user":{"displayName":"Guilherme Samuel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5zFr3jUWJ1NdrUB6KSy3C4B0uR2RLqUiKRzi0S2M=s64","userId":"17398030156076443435"}}},"source":["class RegressaoLinear():\r\n","    def __init__(self, classificador, previsao): # Construtor\r\n","        '''inicializa todas as variaveis necessarias ao instanciar a classe'''\r\n","        self.classificador = np.array(classificador)\r\n","        self.classificadorLista = classificador\r\n","        self.previsao = np.array(previsao)\r\n","        self.previsaoLista = previsao\r\n","        self.verificaSeHouveTreinamento = False\r\n","        self.w0 = 0.1\r\n","        self.w1 = 0.1\r\n","\r\n","    def VisualizarHipotese(self, x, titulo=\"Grafico\"):\r\n","        '''Cria um gráfico com a hipotese de w0 e w1 no instante que o método é chamado'''\r\n","        x = np.array(x)\r\n","        self.hipotese = self.w0 + self.w1*x\r\n","\r\n","        plt.scatter(self.classificador, self.previsao)\r\n","        plt.plot(self.classificador, self.hipotese)\r\n","        plt.title(titulo)\r\n","        plt.show()\r\n","\r\n","    def Hipotese(self, x):\r\n","        '''Calcula a hipotese baseada nos valores de w0 e w0'''\r\n","        return self.w0 + self.w1*x\r\n","\r\n","    def MSE(self, x):\r\n","        '''Faz o calculo do Mean square error(a media do erro) soma todas as distancias dos valores\r\n","         corretos menos a hipotese dividido pela quantidade de valores corretos'''\r\n","        x = np.array(x)\r\n","        '''Calcula a hipotese'''\r\n","        self.y = self.w0 + self.w1 * x\r\n","\r\n","        mse = 0\r\n","        '''Soma todos os erros'''\r\n","        for i in range(0, len(self.y)):\r\n","            mse += (self.previsao[i] - self.y[i])**2\r\n","        '''Calcula a média'''\r\n","        mse = mse / len(self.previsao)\r\n","\r\n","\r\n","        return mse\r\n","\r\n","    def DescidaGradienteStep(self, alpha=0.01, epocas = 5000):\r\n","        '''Atualiza os valores de w0 e w1 afim de minimizar o MSE / taxa de aprendizagem e epocas ja vem com valores pré definidos\r\n","         de 0,01 e 5000 para alterar basta passar como parametro do método'''\r\n","        '''------------------------------------------------------'''\r\n","\r\n","        '''Cria uma lista com a quantidade de iterações do algoritmo para plotar o gráfico de custo'''\r\n","        self.verificaSeHouveTreinamento = True\r\n","        self.eixoX = []\r\n","        for i in range(0, epocas):\r\n","            self.eixoX.append(i)\r\n","\r\n","\r\n","\r\n","        tamanho = len(self.classificador)\r\n","        m = float(len(self.classificadorLista))\r\n","        self.custo = []\r\n","\r\n","        '''executa o algoritmo a quantidade de épocas determinada'''\r\n","        for i in range(0, epocas):\r\n","            '''cria uma lista com o valor do MSE a cada iteração do gráfico para plotar o gráfico depois'''\r\n","            self.custo.append(self.MSE(self.classificadorLista))\r\n","            '''Reseta as váriaveis'''\r\n","            erro_w0 = 0\r\n","            erro_w1 = 0\r\n","\r\n","            '''Executa a somatoria dos erros dos valores preditos pelos valores corretos'''\r\n","            for j in range(0, tamanho):\r\n","                erro_w0 += self.Hipotese(self.classificadorLista[j]) - self.previsaoLista[j]\r\n","                erro_w1 += (self.Hipotese(self.classificadorLista[j]) - self.previsaoLista[j]) * self.classificadorLista[j]\r\n","\r\n","                '''Atualiza os valores de w0 e w1 baseado nos erros de w0 e w1'''\r\n","                self.w0 = self.w0 - alpha * (1/m) * erro_w0\r\n","                self.w1 = self.w1 - alpha * (1/m) * erro_w1\r\n","\r\n","\r\n","    def Prever(self, x):\r\n","        # print(self.w0 + self.w1*x)\r\n","        return print(self.w0 + self.w1*x)\r\n","\r\n","    def VisualizarGraficoErro(self):\r\n","        try:\r\n","            plt.plot(self.eixoX, self.custo)\r\n","            plt.show()\r\n","        except AttributeError:\r\n","            print(\"Primeiro execute o método de descida do gradiente para depois executar esse método\\nFirst run the gradient descent method and then perform this method\")"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QTPSKGc4hLCO","executionInfo":{"status":"ok","timestamp":1615655481164,"user_tz":180,"elapsed":820,"user":{"displayName":"Guilherme Samuel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5zFr3jUWJ1NdrUB6KSy3C4B0uR2RLqUiKRzi0S2M=s64","userId":"17398030156076443435"}},"outputId":"f91e068e-604c-41ab-cf54-89d289d450b8"},"source":["x = [15, 16, 17, 18, 19, 20]\r\n","y = [2, 3, 4, 5, 6, 7]\r\n","\r\n","reg = RegressaoLinear(x, y)\r\n","\r\n","reg.DescidaGradienteStep(epocas = 10000)\r\n","reg.Prever(15) # Esperado 2.00\r\n","reg.Prever(20) # Esperado 7.00\r\n","reg.Prever(25)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["2.0003173819309037\n","7.000165910050395\n","12.000014438169888\n"],"name":"stdout"}]}]}